---
title: "Data analysis project"
author: "Jess Qualley and Rebecca Hansen"
date: "March 27, 2020"
output: word_document
---

##Clear code (**delete before submitting***)
```{r}
rm(list = ls(all = TRUE))
```

#Preparation
##Loading and citing packages
```{r, echo = TRUE}
#Load faraway package
library(faraway)

#Load plyr package
library(plyr)

#Load tidyverse package
library(tidyverse)

#Load lmer package
library(lme4)

#Cite packages
citation("faraway")
citation("plyr")
citation("tidyverse")
```

##Read in and organize data
```{r, echo = TRUE}
#Read from csv file
herring <- read.csv("HerringOtolithDatabase 15 Jan 2020_JQ.csv", header=TRUE, fileEncoding="UTF-8-BOM", stringsAsFactors = FALSE)

#Create a data frame
herring_data <- data.frame(oto.width = herring$AverageWidth,
                           sal.id = herring$FishCode,
                           sal.length = herring$SalmonLength,
                           coll.doy = herring$CollectionDayofYear,
                           lat = herring$Latitude,
                           long = herring$Longitude,
                           
                           sal.sp = herring$SalmonSpecies,
                           coll.year = herring$CollectionYear,
                           stat.area = as.factor(herring$StatArea),
                           
                           digestion = herring$Digestion,
                           sal.sex = herring$SalmonSex,
                           coll.month = herring$CollectionMonth)

#check data frame structure
str(herring_data)

#figure out which stat areas to remove
levels(as.factor(herring$StatArea))

#filter for 2018 data, chinook salmon only, omit northern BC areas (Haid Gwaii) and west coast Vancouver Island
herring_data <- herring_data %>% filter(herring_data$sal.sp == "ch" & herring_data$coll.year == "2018" & herring_data$stat.area != "1" & herring_data$stat.area != "101" & herring_data$stat.area != "125" & herring_data$stat.area != "23" & herring_data$stat.area != "25")
```


#Section 1: Introduction, Question, Goals and Hypotheses (400 words)

##A)
Pacific Salmon in British Columbia are valued for their social, cultural and economic benefits to many communities on our coast. Despite their important role in the coastal marine ecosystem (Schindler et al. 2003), diet studies from this region are outdated and limited to summer sampling. The adult Chinook and Coho Salmon Diet Program (Juanes Lab) seeks to address these knowledge gaps by sourcing stomach samples from the recreational fishing community to gather regional, seasonal and interannual diet data to monitor ecosystem response to environmental change.

We have found Pacific Herring are the dominant fish consumed throughout regions of the Salish Sea, year-round. For this project we will investigate factors that may be important to the size of herring consumed by Chinook Salmon. Previous work found a positive, linear relationship between otolith width (mm) and length (mm) of herring from this dataset (Murchy et al. 2017). Otolith width (mm) measurements averaged from left and right otoliths will be used as a proxy for herring size (Stevenson and Campana, 1992) in this analysis. We will also use salmon catch data recorded by each angler and submitted with the associated stomach sample.

##B)
How does Chinook size, catch location and time of year in the Salish Sea affect the size of herring prey consumed?

##C)
This analysis is descriptive, with the goal of showing how explanatory variables describe patterns in herring size consumed by Chinook in the Salish Sea.

##D)
We hypothesize that otolith width will be positively linear then asymptotic at maximum herring size as salmon length increases. Otolith width and day of year will show a quadratic, s-shaped relationship with the vertex midway through the calendar year. We expect a moderately positive, linear relationship with increasing latitude and a quadratic, concave up relationship with longitude with maximum herring size occurring in mid-channel waters. We expect that collinearity between latitude and longitude will cause in interaction effect on otolith width. An interaction may also exist between salmon length and latitude and between salmon length and day of year.

##E)
We will use AIC fit with maximum likelihood estimation because it is flexible when comparing complex, non-nested models with parameters estimated from ecological field studies. AIC is commonly used in ecosystem studies where parameter estimates are relatively imprecise and we accept that the optimal model may be selected over the true, given the current sample size and our ecological understanding of the system.

(400)

#Section 2: The Response Variable (150 words)
##A)
```{r, fig.width = 6,fig.height = 3}
par(mfrow = c(1, 2))

#Add column for number of rows
n <- nrow(herring_data)
herring_data$row <- 1:n

#Dotchart of otolith width (response variable)
with(herring_data, plot(oto.width, row, las = 1, type = "n", xlab = "Otolith width [mm]", ylab = "Row Number"))
abline (h = seq(1, n, by = 5), col = "lightgrey")
with(herring_data, points(oto.width, row, las = 1, type = "p", pch = 19, cex = 0.5))

#Histogram of response variable with rugmarks
hist(herring_data$oto.width, xlim = c(0.3, 2.8), breaks = seq(0.2, 2.8, by = 0.05), col = grey(0.9), main = "Histogram of herring otolith width", xlab = "Herring otolith width")
rug(herring_data$oto.width)

#Checking for zeroes and NAs in otilith width
table(herring_data$oto.width > 0, useNA = "always")

#exclude rows with NAs for continuous variables
herring_data <- herring_data %>% na.omit()

#add columns for standardized continuous predictor variable for modelling - minus mean / 1 sd
herring_data$sal.length_standardized <- (herring_data$sal.length - mean(herring_data$sal.length)) / sd(herring_data$sal.length)
herring_data$coll.doy_standardized <- (herring_data$coll.doy - mean(herring_data$coll.doy)) / sd(herring_data$coll.doy)
herring_data$lat_standardized <- (herring_data$lat - mean(herring_data$lat)) / sd(herring_data$lat)
herring_data$long_standardized <- (herring_data$long - mean(herring_data$long)) / sd(herring_data$long)
```

##B) 
The response variable (otolith width) is continuous and cannot take on zero or negative values. The range of possible response values in this dataset is 0.007 mm to 2.68 mm. 

##C)
Outliers at < 0.6 mm and > 2.2 mm are reasonable measurements representing a few individuals in the extreme age classes. There are no zero values and one missing otolith measurement making up 0.11 % of the data. We anticipate no difficulties in removing the single NA value from subsequent analyses. Non-independence is expected from repeated measurements of multiple herring that occurred within the same salmon stomach. Herring consumed at similar times of year may have similar growth trajectories that contribute to temporal autocorrelation. Spatial autocorrelation may occur if herring consumed in similar areas have similar prey fields and grow rates.

##D)
We will consider the normal distribution for modelling.  

(140)

#Section 3: The Explanatory Variables (150 words)
##A)
###Continuous explanatory variables
```{r, fig.width = 6,fig.height = 6}
#Multipanel of dotcharts for continuous explanatory variables
par(mfrow = c(3, 2))

#Salmon length
with(herring_data, plot(sal.length, row, las = 1, type = "n", xlab = "Actual Salmon Length [mm]", ylab = "Row Number"))
abline (h = seq(1, n, by = 5), col = "lightgrey")
with(herring_data, points(sal.length, row, las = 1, type = "p", pch = 19, cex = 0.5))

#Collection day of year
with(herring_data, plot(coll.doy, row, las = 1, type = "n", xlab = "Day of Year in 2018", ylab = "Row Number"))
abline (h = seq(1, n, by = 5), col = "lightgrey")
with(herring_data, points(coll.doy, row, las = 1, type = "p", pch = 19, cex = 0.5))

#Latitude
with(herring_data, plot(lat, row, las = 1, type = "n", xlab = "Latitude", ylab = "Row Number"))
abline (h = seq(1, n, by = 5), col = "lightgrey")
with(herring_data, points(lat, row, las = 1, type = "p", pch = 19, cex = 0.5))

#Longitude
with(herring_data, plot(long, row, las = 1, type = "n", xlab = "Longitude", ylab = "Row Number"))
abline (h = seq(1, n, by = 5), col = "lightgrey")
with(herring_data, points(long, row, las = 1, type = "p", pch = 19, cex = 0.5))

#Multipanel of histograms for continuous explanatory variables
par(mfrow = c(3, 2))

#Salmon length
hist(herring_data$sal.length, col = grey(0.9), breaks = seq(40, 100, by = 1), main = "Histogram of salmon length", xlab = "Salmon length")
rug(herring_data$sal.length)

#Collection day of year
hist(herring_data$coll.doy, col = grey(0.9), breaks = seq(0, 400, by = 7), main = "Histogram of day of year", xlab = "Collection day of year")
rug(herring_data$coll.doy)

#Latitude *something is up with this y axis
hist(herring_data$lat, col = grey(0.9), breaks = seq(48.0, 51.0, by = 0.05), main = "Histogram of latitude", xlab = "Latitude")
rug(herring_data$lat)

#Longitude
hist(herring_data$long, col = grey(0.9), breaks = seq(-125.5, -123, by = 0.05), main = "Histogram of longitude", xlab = "Longitude")
rug(herring_data$long)

```

###Categorical explanatory variables
```{r, fig.width = 6,fig.height = 3}
#Multipanel of dotcharts for categorical explanatory variables
par(mfrow = c(1, 2))

#Salmon id *is this useful? Shows that ID increases as we would expect.
with(herring_data, plot(sal.id, row, las = 1, type = "n", xlab = "Salmon ID", ylab = "Row Number"))
abline (h = seq(1, n, by = 5), col = "lightgrey")
with(herring_data, points(sal.id, row, las = 1, type = "p", pch = 19, cex = 0.5))

#Make a histogram of herring frequency per salmon *bins are off unsure why
hist(herring_data$sal.id, col = grey(0.9), bin = seq(17300, 18200, by = 1), main = "Histogram of Salmon ID", xlab = "Salmon ID")

#Make a table of salmon sex, digestion, collection month
with(herring_data, table(sal.sex, digestion)) #is this useful? Just shows digestion of herring vs. sex of salmon - perhaps omit. How important is it to reference digestion at all if we are not including it in our model?
with(herring_data, table(digestion, coll.month)) #useful to show herring per month
with(herring_data, table(sal.sex, coll.month)) #useful to show salmon per month
```
## B)
One outlier is observed at 45cm and three outliers at 90 - 100cm. However, these are reasonable sizes for recreationally caught chinook salmon. No transformations are necessary as no obvious skewedness is observed.

(33)

#Section 4: Collinearity, Balance, and Variance Inﬂation Factors (200 words)
##A)
```{r, echo = TRUE}
#create data frame for pairwise scatter with only continuous explanatory variables - salmon lenght, weight, collection day of year, latitude and longitude
herring_collinearity <- data.frame("sal.length" = herring_data$sal.length, "coll.doy" = herring_data$coll.doy, "lat" = herring_data$lat, "long" = herring_data$long)

#Pairwise scatterplot of explanatory variables (salmon length, weight, day of year, latitude and longitude)
plot(herring_collinearity[1:4], cex = 0.5, pch = 19, col = rgb(0, 0, 0, 0.5), 
                   labels = c("Chinook\nLength [mm]", "Collection\nDay in 2018", "Latitude", "Longitude"))

#Pairwise correlation coefficients for explanatory variables
print(cor(na.omit(herring_data[ ,c("sal.length", "coll.doy", "lat", "long")])), digits = 2)

#Variance Inflation Factors
print(vif(na.omit(herring_data[ ,c("sal.length", "coll.doy", "lat", "long")])))
```
Tables in section 3 indicate more herring and salmon were collected between March and July (316) compared to other months (124). More females (218) were caught compared to males (139) and 83 fish were left unsexed. We should be cautious about drawing conclusions from models that include sex or collection month as any estimates may be driven by unbalanced variables.

Pairwise scatterplots suggest a concave up relationship between salmon length and collection day of year with a weak correlation coefficient of -0.062, perhaps due to seasonality of salmon caught during the spring and summer months. Salmon length is moderately, positively correlated (0.449) with latitude but moderately, negatively correlated longitude (-0.3991). There is a weak, slightly negative correlation (-0.1284) between collection day of year and latitude but a strong, negative correlation (-0.8721) between latitude and longitude. VIF values of latitude (4.721313) and longitude (4.428887) are greater than 3 and strongly colinear, which is expected due to the geographical constraints of the Strait of Georgia and Juan de Fuca. We will run models with either latitude or longitude to avoid the confounding effects of including both variables in a single model. 

(196)

*address doy issue in discussion
*maybe include totals in tables

#Section 5: Statistical Methods and Model Fitting (200 words)

We will be using linear mixed-effects models using the R Package lme4 (Bates et al., 2015). We are considering the normal distribution of otolith width (mm) modelled as function of salmon length (mm), day of year in 2018, latitude and longitude. We will include a random intercept corresponding to individual salmon because there are > 10 levels (ref.). Ecologically, it is likely that multiple herring in one stomach have similar sizes if they travel in the same school targeted by an individual. We are excluding salmon sex and collection month due to unbalancing effects and excluding digestion level, which is the degree of herring degradation on a scale of 1 to 4, as it is not relevant to our research question. In our first round of modelling fitting all salmon lengths will be included followed by a second round of model fitting to salmon 62 cm and above as this is the regulation size restrictions for recreationally caught salmon in the Strait of Georgia. This will check the influence of removing under size regulation fish from the dataset.

(178)

## Exploratory plotting
```{r}
#create data frame for pairwise scatter with all variables
herring_collinearity <- data.frame("sal.id" = herring_data$sal.id, "oto.width" = herring_data$oto.width, "sal.length" = herring_data$sal.length, "coll.doy" = herring_data$coll.doy, "lat" = herring_data$lat, "long" = herring_data$long)

plot(herring_collinearity[1:6], cex = 0.5, pch = 19, col = rgb(0, 0, 0, 0.5), 
                   labels = c("Salmon ID", "Otolith Width (mm)", "Chinook\nLength [mm]", "Collection\nDay in 2018", "Latitude", "Longitude"))
```


## Model Structure

oto.width ~ coll.doy + lat + sal.length + (1 | sal.id)
oto.width ~ coll.doy + long + sal.length + (1 | sal.id)

1. oto.width ~ coll.doy + lat + coll.doy:lat + (1 | sal.id)
2. oto.width ~ coll.doy + sal.length + coll.doy:sal.length + (1 | sal.id)
3. oto.width ~ lat + sal.length + lat:sal.length + (1 | sal.id)
4. oto.width ~ coll.doy + long + coll.doy:long + (1 | sal.id)
5. oto.width ~ long + sal.length + long:sal.length + (1 | sal.id)



## Fit Statistical Models *I think these are wrong - must go from complex to simple...
```{r}
model1 <- lmer(oto.width ~ coll.doy_standardized + lat_standardized + coll.doy_standardized:lat_standardized + (1 | sal.id), data = herring_data, REML = FALSE)
model2 <- lmer(oto.width ~ coll.doy_standardized + sal.length_standardized + coll.doy_standardized:sal.length_standardized + (1 | sal.id), data = herring_data, REML = FALSE)
model3 <- lmer(oto.width ~ lat_standardized + sal.length_standardized + lat_standardized:sal.length_standardized + (1 | sal.id), data = herring_data, REML = FALSE)
model4 <- lmer(oto.width ~ coll.doy_standardized + long_standardized + coll.doy_standardized:long_standardized + (1 | sal.id), data = herring_data, REML = FALSE)
model5 <- lmer(oto.width ~ long_standardized + sal.length_standardized + long_standardized:sal.length_standardized + (1 | sal.id), data = herring_data, REML = FALSE)
```

#Section 6: Model Checking 
##plotting residuals of at least 1 model (delete before submitting?)
```{r}
#try checking assumptions of model 4 (retroactively, since AIC showed this model has a relatively good goodness-of-fit compared to the other candidate models)
par(mfrow = c(2, 2))

#plot residuals versus fitted values
plot(resid(model4) ~ predict(model4))
abline(h = 0, lty = "dashed")

#plot residual as probability density then add rug marks and a reference curve
hist(resid(model4), prob = TRUE, col = "lightgrey")
rug(resid(model4))
sd_hat <- sd(resid(model4))
curve(dnorm(x, sd = sd_hat), add = TRUE)

#make quantile-quantile plot and add reference line * do we need this?
qqnorm(resid(model4))
qqline(resid(model4), col = "red")

#quantile-quantile plot for linear mixed-effects model additional assumption - does the random intercept have a norml distribution?
qqnorm(ranef(model4)$sal.id[, "(Intercept)"])
qqline(ranef(model4)$sal.id[, "(Intercept)"])

#run a Shapiro-Wilk test for normality of the residuals
shapiro.test(resid(model4))
```
1. Written summary (200 words)
-assessment of plausibility of model assumptions (LINE)
-check for correlation in the residuals due to grouping variables (e.g., repeated measurements on individuals or within study sites), spatial autocorrelation and/or temporal autocorrelation
-comment on potential outliers, as relevant


#Section 7: Model Summary, Conﬁdence Intervals and Model Comparison 

```{r, echo = TRUE}
#Model comparison and/or model selection and/or hypothesis testing

#AIC (or AICc) values
AIC_out <- AIC(model1, model2, model3, model4, model5)
AIC_out$delta_AIC <- AIC_out$AIC - min(AIC_out$AIC)
AIC_out

#AIC (or AICc) weights
bbmle::AICtab(model1, model2, model3, model4, model5, base = TRUE, weights = TRUE)

#R-squared (or adjusted R-squared) values
#p-values - note: cannot compute pvalues because the number of herring per salmon is unbalanced - chapter 5, page 9


#Summary for at least one ﬁtted model - see chapter 5, page 19
#coeﬃcient estimates for fixed and random  effects (random effects correspond to  2 sources of variation = variation between individuals and residual variation between observations)
model4
summary(model4)

#conﬁdence intervals for coeﬃcient estimate
confint(model4)

#rearranging data to make coefficient plots to show standard errors:

#data frame for coefficient plot
confint_fixed <- as.data.frame(confint(model4, parm = c("(Intercept)", "coll.doy_standardized", "long_standardized", "coll.doy_standardized:long_standardized")))

#compute profile confidence intervals
confint_fixed <- as.data.frame(confint_fixed)
confint_fixed$term <- rownames(confint_fixed)
confint_fixed$estimate <- fixef(model4)

#ggplot
ggplot(confint_fixed) + theme_bw() +
geom_point(aes(y = term, x = estimate), colour = "midnightblue") +
geom_errorbarh(aes(y = term, xmin = `2.5 %`, xmax = `97.5 %`), colour = "midnightblue", height = 0.3) +
scale_y_discrete(labels = c("Intercept", "Collection Day of Year", "Longitude", "Collection Day of Year : Longitude")) +
xlab("") +
ylab("") + ggtitle("Coefficient Estimates for model4_standardized") +
theme(axis.text = element_text(size = 14, colour = "black"))
```

#Section 8: Plotting a Model with the Data

```{r, echo = TRUE}
#Plot at least one model with data
#- use method that shows strengths and weaknesses
#- include measurement of uncertainty

par(mfrow = c(2, 2))
plot(resid(model4) ~ herring_data$sal.length, xlab = "Salmon Length [cm]", ylab = "Residuals(model4)", main = "", font.main = 1)
plot(resid(model4) ~ herring_data$coll.doy, xlab = "Collection Day of Year", ylab = "Residuals(model4)", main = "", font.main = 1)
plot(resid(model4) ~ herring_data$lat, xlab = "Latitude", ylab = "Residuals(model4)", main = "", font.main = 1)
plot(resid(model4) ~ herring_data$long, xlab = "Longitude", ylab = "Residuals(model4)", main = "", font.main = 1)

#Generate 95% prediction intervals for the fitted mean of the quadratic model
newdata <- data.frame(temp = seq(10, 100, by = 1))
newdata$fit1 <- predict(model4, newdata = newdata)
newdata$upr1 <- predict(model4, newdata = newdata, interval = "prediction")[, "upr"]
newdata$lwr1 <- predict(model4, newdata = newdata, interval = "prediction")[, "lwr"]

```

#Section 9: Discussion (400 words)
##A)
Assessment of how well the model seems to ﬁt the data
- model checking
- visualization of the model with the data
- 
##B)
Qualitative interpretation of the model
- interpretation of results in relation to your research questions and hypotheses
- general interpretation of conﬁdence intervals or standard errors for coeﬃcient estimates
-
##C)
Limitations of the model(s) that you have ﬁt
- Limitations
- Possible options for improvement
- Possible approaches for further data analysis

##D)
Results into context
- citie at least two relevant scientiﬁc papers

## References

Schindler, D. E., M. D. Scheuerell, J. W. Moore, S. M. Gende, T. B. Francis, and W. J. Palen. 2003. Pacific Salmon and the Ecology of Coastal Ecosystems. Frontiers in Ecology and the Environment 1:31.

Stevenson, D. K., and S. E. Campana. 1992. Otolith microstructure examination and analysis. Can. Spec. Publ. Fish. Aquat. Sci. 117: 126 p. 1. Page Otolith Microstructure Examination and Analysis.

Bates, D., Maechler, M., Bolker, B., Walker, S., 2015. Fitting Linear Mixed-Effects Models Using lme4.
Journal of Statistical Software, 67 (1), 1-48.

