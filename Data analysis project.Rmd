---
title: "Data analysis project"
author: "Jess Qualley and Rebecca Hansen"
date: "March 27, 2020"
output: word_document
---

##Clear code (**delete before submitting***)
```{r}
rm(list = ls(all = TRUE))
```

#Preparation
##Loading and citing packages
```{r, echo = TRUE}
#Load faraway package
library(faraway)

#Load plyr package
library(plyr)

#Load tidyverse package
library(tidyverse)

#Load gridextra package
library(gridExtra)

#Load lmer package
library(lme4)

#Load bbmle package
library(bbmle)

#Cite packages
citation("faraway")
citation("plyr")
citation("tidyverse")
citation("bbmle")
citation("gridExtra")
```

##Read in and organize data
```{r, echo = TRUE}
#Read from csv file
herring <- read.csv("HerringOtolithDatabase 15 Jan 2020_JQ.csv", header=TRUE, fileEncoding="UTF-8-BOM", stringsAsFactors = FALSE)

#Create a data frame
herring_data <- data.frame(oto.width = herring$AverageWidth,
                           sal.id = herring$FishCode,
                           sal.length = herring$SalmonLength,
                           coll.doy = herring$CollectionDayofYear,
                           lat = herring$Latitude,
                           long = herring$Longitude,
                           coll.month = herring$CollectionMonth,
                           
                           sal.sp = herring$SalmonSpecies,
                           coll.year = herring$CollectionYear,
                           stat.area = as.factor(herring$StatArea))

#Filter for 2018 chinook salmon only, omit northern BC areas (Haid Gwaii) and west coast Vancouver Island
herring_data <- herring_data %>% filter(herring_data$sal.sp == "ch" & herring_data$coll.year == "2018" & herring_data$stat.area != "1" & herring_data$stat.area != "101" & herring_data$stat.area != "125" & herring_data$stat.area != "23" & herring_data$stat.area != "25")
```


#Section 1: Introduction, Question, Goals and Hypotheses (400 words)

##A)
Pacific Salmon in British Columbia are valued for their social, cultural and economic benefits to many communities on our coast. Despite their important role in the coastal marine ecosystem (Schindler et al. 2003), diet studies from this region are outdated and limited to summer sampling. The adult Chinook and Coho Salmon Diet Program (Juanes Lab) seeks to address these knowledge gaps by sourcing stomach samples from the recreational fishing community to gather regional, seasonal and interannual diet data to monitor ecosystem response to environmental change.

We have found Pacific Herring are the dominant fish consumed throughout regions of the Salish Sea, year-round. For this project we will investigate factors that may be important to the size of herring consumed by Chinook Salmon. Previous work found a positive, linear relationship between otolith width (mm) and length (mm) of herring from this dataset (Murchy et al. 2017). Otolith width (mm) measurements averaged from left and right otoliths will be used as a proxy for herring size (Stevenson and Campana, 1992) in this analysis. We will also use salmon catch data recorded by each angler and submitted with the associated stomach sample.

##B)
How does Chinook size, catch location and time of year in the Salish Sea affect the size of herring prey consumed?

##C)
This analysis is descriptive, with the goal of showing how explanatory variables describe patterns in herring size consumed by Chinook in the Salish Sea.

##D)
We hypothesize that otolith width will be positively linear as salmon length increases. Otolith width and day of year will show a positive linear relationship with the calendar year. We expect a moderately positive, linear relationship with increasing latitude. We expect a negative linear relationship with longitude if larger herring occur along west Strait of Georgia. However, we could see a non-linear relationship with longitude if maximum herring size occurrs in mid-channel waters. We expect an interaction between salmon length and latitude, as there productivity in northern regions. An interaction between salmon length and longitude may occur if mainland stocks and those on Vancouver Island differ in size. We expect an interaction between salmon length and day of year, as each age class grows through the year.

##E)
We will use AIC fit with maximum likelihood estimation because it is flexible when comparing complex, non-nested models with parameters estimated from ecological field studies. AIC is commonly used in ecosystem studies where parameter estimates are relatively imprecise and we accept that the optimal model may be selected over the true, given the current sample size and our ecological understanding of the system.

(400)

#Section 2: The Response Variable (150 words)
##A)
```{r, fig.width = 6,fig.height = 3}
par(mfrow = c(1, 2))

#Add column for number of rows
n <- nrow(herring_data)
herring_data$row <- 1:n

#Make dotchart of otolith width (response variable)
with(herring_data, plot(oto.width, row, las = 1, type = "n", xlab = "Otolith width [mm]", ylab = "Row Number"))
abline (h = seq(1, n, by = 5), col = "lightgrey")
with(herring_data, points(oto.width, row, las = 1, type = "p", pch = 19, cex = 0.5))

#Make histogram of response variable with rugmarks
hist(herring_data$oto.width, xlim = c(0.3, 2.8), breaks = seq(0.2, 2.8, by = 0.05), col = grey(0.9), main = "Histogram of herring otolith width", xlab = "Herring otolith width")
rug(herring_data$oto.width)

#Check for zeroes and NAs in otilith width
table(herring_data$oto.width > 0, useNA = "always")

#Exclude rows with NAs for continuous variables
herring_data <- herring_data %>% na.omit()
```

##B) 
The response variable (otolith width) is continuous and cannot take on zero or negative values. The range of possible response values in this dataset is 0.007 mm to 2.68 mm. 

##C)
Outliers at < 0.6 mm and > 2.2 mm are reasonable measurements representing a few individuals in the extreme age classes. There are no zero values and one missing otolith measurement making up 0.11 % of the data. We anticipate no difficulties in removing the single NA value from subsequent analyses. Non-independence is expected from repeated measurements of multiple herring that occurred within the same salmon stomach. Herring consumed at similar times of year may have similar growth trajectories that contribute to temporal autocorrelation. Spatial autocorrelation may occur if herring consumed in similar areas have similar prey fields and grow rates.

##D)
We will consider the normal distribution for modelling.  

(140)

#Section 3: The Explanatory Variables (150 words)
##A)
###Continuous explanatory variables
```{r, fig.width = 6,fig.height = 6}
#Make multipanel of dotcharts for continuous explanatory variables
par(mfrow = c(3, 2))

#Salmon length dotchart
with(herring_data, plot(sal.length, row, las = 1, type = "n", xlab = "Actual Salmon Length [mm]", ylab = "Row Number"))
abline (h = seq(1, n, by = 5), col = "lightgrey")
with(herring_data, points(sal.length, row, las = 1, type = "p", pch = 19, cex = 0.5))

#Collection day of year dotchart
with(herring_data, plot(coll.doy, row, las = 1, type = "n", xlab = "Day of Year in 2018", ylab = "Row Number"))
abline (h = seq(1, n, by = 5), col = "lightgrey")
with(herring_data, points(coll.doy, row, las = 1, type = "p", pch = 19, cex = 0.5))

#Latitude dotchart
with(herring_data, plot(lat, row, las = 1, type = "n", xlab = "Latitude", ylab = "Row Number"))
abline (h = seq(1, n, by = 5), col = "lightgrey")
with(herring_data, points(lat, row, las = 1, type = "p", pch = 19, cex = 0.5))

#Longitude dotchart
with(herring_data, plot(long, row, las = 1, type = "n", xlab = "Longitude", ylab = "Row Number"))
abline (h = seq(1, n, by = 5), col = "lightgrey")
with(herring_data, points(long, row, las = 1, type = "p", pch = 19, cex = 0.5))

#Make multipanel of histograms for continuous explanatory variables
par(mfrow = c(3, 2))

#Salmon length histogram
hist(herring_data$sal.length, col = grey(0.9), breaks = seq(40, 100, by = 1), main = "Histogram of salmon length", xlab = "Salmon length")
rug(herring_data$sal.length)

#Collection day of year histogram
hist(herring_data$coll.doy, col = grey(0.9), breaks = seq(0, 400, by = 7), main = "Histogram of day of year", xlab = "Collection day of year")
rug(herring_data$coll.doy)

#Latitude histogram
hist(herring_data$lat, col = grey(0.9), breaks = seq(48.0, 51.0, by = 0.05), main = "Histogram of latitude", xlab = "Latitude")
rug(herring_data$lat)

#Longitude histogram
hist(herring_data$long, col = grey(0.9), breaks = seq(-125.5, -123, by = 0.05), main = "Histogram of longitude", xlab = "Longitude")
rug(herring_data$long)

```

###Categorical explanatory variables
```{r, fig.width = 6,fig.height = 3}
#Make multipanel for plots of categorical explanatory variables
par(mfrow = c(1, 2))

#Make dotchart of salmon id
with(herring_data, plot(sal.id, row, las = 1, type = "n", xlab = "Salmon ID", ylab = "Row Number"))
abline (h = seq(1, n, by = 5), col = "lightgrey")
with(herring_data, points(sal.id, row, las = 1, type = "p", pch = 19, cex = 0.5))

#Make a histogram of herring frequency per salmon
hist(herring_data$sal.id, col = grey(0.9), breaks = seq(17300, 18200, by = 1), main = "Histogram of Salmon ID", xlab = "Salmon ID")
```
## B)
One outlier is observed at 45cm and three outliers at 90 - 100cm. However, these are reasonable sizes for recreationally caught chinook salmon. No transformations are necessary as no substantial skewedness is observed.

(33)

#Section 4: Collinearity, Balance, and Variance Inﬂation Factors (200 words)
##A)
```{r, echo = TRUE}
#Create dataframe for pairwise scatter plots that only includes continuous explanatory variables - salmon lenght, weight, collection day of year, latitude and longitude
herring_collinearity <- data.frame("sal.length" = herring_data$sal.length,
    "coll.doy" = herring_data$coll.doy, "lat" = herring_data$lat, "long" = herring_data$long)

#Make pairwise scatterplot of explanatory variables
plot(herring_collinearity[1:4], cex = 0.5, pch = 19, col = rgb(0, 0, 0, 0.5), 
     labels = c("Chinook\nLength [mm]", "Collection\nDay in 2018", "Latitude", "Longitude"))

#Plot mean salmon size vs. collection month
boxplot(sal.length ~ coll.month, data = herring_data)

#Calculate and view pairwise correlation coefficients for explanatory variables
print(cor(na.omit(herring_data[ ,c("sal.length", "coll.doy", "lat", "long")])), digits = 2)

#Calulate and view Variance Inflation Factors
print(vif(na.omit(herring_data[ ,c("sal.length", "coll.doy", "lat", "long")])))
```
  
Our only categorical variable is salmon id so the range in the number of otoliths per salmon was x to x will not confounded any other categorical variables. We plan to model salmon id as a random effect which will account for the effects of any unbalancing associated with salmon id on the continuous variables.  
  
A boxplot of mean salmon length per month shows that mean salmon length in summer months overlapped with mean salmon length observed in earlier months in the year, likely due to unbalanced sampling effort over the year as opposed to the concave up shape observed in the pairwise scatterplot. The remaining relationships observed in the pairwise scatterplots were consistent with the pairwise correlation coefficients. Salmon length was moderately, positively correlated (0.449) with latitude but moderately, negatively correlated longitude (-0.3991). There was a strong, negative correlation (-0.8721) between latitude and longitude. VIF values of latitude (4.721313) and longitude (4.428887) were greater than 3 and strongly colinear, which is expected due to the geographical constraints of the Strait of Georgia and Juan de Fuca. We will run models with either latitude or longitude to avoid the confounding effects of including both variables in a single model.  
  
(204)  

*get otolith number per salmon id range
  
#Section 5: Statistical Methods and Model Fitting (200 words)

We will be using linear mixed-effects models using the R Package lme4 (Bates et al., 2015). We are assuming that otolith width (mm), our response variable, is normally distributed as suggested by a histogram of otolith width. We will model otolith width (mm) as function of salmon length (cm), day of year in 2018, latitude and longitude. Dotplots and histograms of these predictor variables show few missing values or outliers so the data from these variables can be used for modelling. There wasn't strong colinearity between predictor variables except for longitude and latitude, which we will not include in the same model. We have chosen to standardize our predictor variables as they were measured on vastly different scales. We will include a random intercept corresponding to individual salmon (salmon id) to avoid autocorrelation from non-independence of multiple herring that may occur in a single salmon or experimental unit. Ecologically, it is likely that multiple herring in one stomach have similar sizes if they travel in the same school targeted by an individual salmon. We have chosen a random intercept for salmon id because the number of levels is greater than 10 (ref.).

(193)

*ref for > 10 levels

##Standardizing data for models
```{r}
#Add columns for standardized  continuous predictor variable for modelling (x - minus mean / 1 sd)
herring_data$sal.length_standardized <- (herring_data$sal.length - mean(herring_data$sal.length)) / sd(herring_data$sal.length)
herring_data$coll.doy_standardized <- (herring_data$coll.doy - mean(herring_data$coll.doy)) / sd(herring_data$coll.doy)
herring_data$lat_standardized <- (herring_data$lat - mean(herring_data$lat)) / sd(herring_data$lat)
herring_data$long_standardized <- (herring_data$long - mean(herring_data$long)) / sd(herring_data$long)
```


##Creating linear mixed-effect models
```{r}
#Intercept-only model
model_0 <- lmer(oto.width ~ (1 | sal.id), data = herring_data)

#Models with one explanatory variable
model_1 <- lmer(oto.width ~ sal.length_standardized + (1 | sal.id), data = herring_data)

model_2 <- lmer(oto.width ~ coll.doy_standardized + (1 | sal.id), data = herring_data)

model_3 <- lmer(oto.width ~ lat_standardized + (1 | sal.id), data = herring_data)

model_4 <- lmer(oto.width ~ long_standardized + (1 | sal.id), data = herring_data)

#Models with two explanatory variables
model_5 <- lmer(oto.width ~ coll.doy_standardized + sal.length_standardized + (1 | sal.id), data = herring_data)

model_6 <- lmer(oto.width ~ coll.doy_standardized + long_standardized  + (1 | sal.id), data = herring_data)

model_7 <- lmer(oto.width ~ coll.doy_standardized + lat_standardized + (1 | sal.id), data = herring_data)

model_8 <- lmer(oto.width ~  sal.length_standardized + long_standardized + (1 | sal.id), data = herring_data)

model_9 <- lmer(oto.width ~  sal.length_standardized + lat_standardized + (1 | sal.id), data = herring_data)

#Models with three explanatory variables
model_10 <- lmer(oto.width ~ coll.doy_standardized + lat_standardized + sal.length_standardized + (1 | sal.id), data = herring_data)

model_11 <- lmer(oto.width ~ coll.doy_standardized + long_standardized + sal.length_standardized + (1 | sal.id), data = herring_data)

#Models with two explanatory variables and one interaction term
model_5i <- lmer(oto.width ~ coll.doy_standardized*sal.length_standardized + (1 | sal.id), data = herring_data)

model_6i <- lmer(oto.width ~ coll.doy_standardized*long_standardized  + (1 | sal.id), data = herring_data)

model_7i <- lmer(oto.width ~ coll.doy_standardized*lat_standardized + (1 | sal.id), data = herring_data)

model_8i <- lmer(oto.width ~  sal.length_standardized*long_standardized + (1 | sal.id), data = herring_data)

model_9i <- lmer(oto.width ~  sal.length_standardized*lat_standardized + (1 | sal.id), data = herring_data)

#Models with three explanatory variables and one interaction term
model_10l <- lmer(oto.width ~ coll.doy_standardized  + lat_standardized*sal.length_standardized + (1 | sal.id), data = herring_data)

model_11l <- lmer(oto.width ~ coll.doy_standardized + long_standardized*sal.length_standardized + (1 | sal.id), data = herring_data)

model_10c <- lmer(oto.width ~ coll.doy_standardized*sal.length_standardized + lat_standardized + (1 | sal.id), data = herring_data)

model_11c <- lmer(oto.width ~ coll.doy_standardized*sal.length_standardized + long_standardized + (1 | sal.id), data = herring_data)

#Models with three explanatory variables and two interaction terms
model_10cl <- lmer(oto.width ~ coll.doy_standardized*sal.length_standardized*lat_standardized + (1 | sal.id), data = herring_data)

model_11cl <- lmer(oto.width ~ coll.doy_standardized*sal.length_standardized*long_standardized + (1 | sal.id), data = herring_data)
```

#Section 6: Model Checking 
##Checking assumptions of model 11
```{r}
#Plot residuals versus fitted values (shown with a smoothing curve)
herring_data$resid_11 <- resid(model_11) 
herring_data$fitted_11 <- predict(model_11, re.form = ~0)

ggplot(herring_data) +
  theme_minimal() + 
  geom_point(aes(fitted_11, resid_11), shape = 1) +
  geom_smooth(aes(fitted_11, resid_11), se = FALSE)

#Make multipanel of residual plots
par(mfrow = c(1, 2))

#Plot histogram of residuals as probability density with rug marks and reference curve
hist(resid(model_11), prob = TRUE, col = "lightgrey")
rug(resid(model_11))
sd_hat <- sd(resid(model_11))
curve(dnorm(x, sd = sd_hat), add = TRUE)

#Make quantile-quantile plot with reference line
qqnorm(resid(model_11))
qqline(resid(model_11), col = "red")

#Run a Shapiro-Wilk test for normality of the residuals
shapiro.test(resid(model_11))

#Make multipanel of residual plots
par(mfrow = c(1, 1))

#Make quantile-quantile plot for checking whether the random intercept is normally distributed
qqnorm(ranef(model_11)$sal.id[, "(Intercept)"])
qqline(ranef(model_11)$sal.id[, "(Intercept)"])

#Plot histogram of residuals as probability density with rug marks and reference curve
ranef_int <- ranef(model_11)$sal.id[, "(Intercept)"]
hist(ranef_int, prob = TRUE, col = "lightgrey")
rug(ranef_int)
sd_hat_int <- sd(ranef_int)
curve(dnorm(x, sd = sd_hat_int), add = TRUE)
```
##Checking assumptions of model 6
```{r}
#Plot residuals versus fitted values (shown with a smoothing curve)
herring_data$resid_6 <- resid(model_6) 
herring_data$fitted_6 <- predict(model_6, re.form = ~0)

ggplot(herring_data) +
  theme_minimal() + 
  geom_point(aes(fitted_6, resid_6), shape = 1) +
  geom_smooth(aes(fitted_6, resid_6), se = FALSE)

#Make multipanel of residual plots
par(mfrow = c(1, 2))

#Plot histogram of residuals as probability density with rug marks and reference curve
hist(resid(model_6), prob = TRUE, col = "lightgrey")
rug(resid(model_6))
sd_hat <- sd(resid(model_6))
curve(dnorm(x, sd = sd_hat), add = TRUE)

#Make quantile-quantile plot with reference line
qqnorm(resid(model_6))
qqline(resid(model_6), col = "red")

#Run a Shapiro-Wilk test for normality of the residuals
shapiro.test(resid(model_6))

#Plot residuals vs. sal.length (shown with smoothing curve)
resid_vs_sal.length_6 <- ggplot(herring_data) +
  theme_minimal() + 
  geom_point(aes(sal.length, resid_6), shape = 1) +
  geom_smooth(aes(sal.length, resid_6), se = FALSE)

#Make multipanel of residual plots
par(mfrow = c(1, 1))

#Make quantile-quantile plot for checking whether the random intercept is normally distributed
qqnorm(ranef(model_6)$sal.id[, "(Intercept)"])
qqline(ranef(model_6)$sal.id[, "(Intercept)"])

#Plot histogram of residuals as probability density with rug marks and reference curve
ranef_int <- ranef(model_6)$sal.id[, "(Intercept)"]
hist(ranef_int, prob = TRUE, col = "lightgrey")
rug(ranef_int)
sd_hat_int <- sd(ranef_int)
curve(dnorm(x, sd = sd_hat_int), add = TRUE)
```
1. Written summary (200 words)

-assessment of plausibility of model assumptions (LINE)
-check for correlation in the residuals due to grouping variables (e.g., repeated measurements on individuals or within study sites), spatial autocorrelation and/or temporal autocorrelation
-comment on potential outliers, as relevant


#Section 7: Model Summary, Conﬁdence Intervals and Model Comparison 
##Rewriting all models with REML= FALSE
```{r, echo = TRUE}
#Intercept-only model
model_0 <- lmer(oto.width ~ (1 | sal.id), data = herring_data, REML= FALSE)

#Models with one explanatory variable
model_1 <- lmer(oto.width ~ sal.length_standardized + (1 | sal.id), data = herring_data, REML= FALSE)

model_2 <- lmer(oto.width ~ coll.doy_standardized + (1 | sal.id), data = herring_data, REML= FALSE)

model_3 <- lmer(oto.width ~ lat_standardized + (1 | sal.id), data = herring_data, REML= FALSE)

model_4 <- lmer(oto.width ~ long_standardized + (1 | sal.id), data = herring_data, REML= FALSE)

#Models with two explanatory variables
model_5 <- lmer(oto.width ~ coll.doy_standardized + sal.length_standardized + (1 | sal.id), data = herring_data, REML= FALSE)

model_6 <- lmer(oto.width ~ coll.doy_standardized + long_standardized  + (1 | sal.id), data = herring_data, REML= FALSE)

model_7 <- lmer(oto.width ~ coll.doy_standardized + lat_standardized + (1 | sal.id), data = herring_data, REML= FALSE)

model_8 <- lmer(oto.width ~  sal.length_standardized + long_standardized + (1 | sal.id), data = herring_data, REML= FALSE)

model_9 <- lmer(oto.width ~  sal.length_standardized + lat_standardized + (1 | sal.id), data = herring_data, REML= FALSE)

#Models with three explanatory variables
model_10 <- lmer(oto.width ~ coll.doy_standardized + lat_standardized + sal.length_standardized + (1 | sal.id), data = herring_data, REML= FALSE)

model_11 <- lmer(oto.width ~ coll.doy_standardized + long_standardized + sal.length_standardized + (1 | sal.id), data = herring_data, REML= FALSE)

#Models with two explanatory variables and one interaction term
model_5i <- lmer(oto.width ~ coll.doy_standardized*sal.length_standardized + (1 | sal.id), data = herring_data, REML= FALSE)

model_6i <- lmer(oto.width ~ coll.doy_standardized*long_standardized  + (1 | sal.id), data = herring_data, REML= FALSE)

model_7i <- lmer(oto.width ~ coll.doy_standardized*lat_standardized + (1 | sal.id), data = herring_data, REML= FALSE)

model_8i <- lmer(oto.width ~  sal.length_standardized*long_standardized + (1 | sal.id), data = herring_data, REML= FALSE)

model_9i <- lmer(oto.width ~  sal.length_standardized*lat_standardized + (1 | sal.id), data = herring_data, REML= FALSE)

#Models with three explanatory variables and one interaction term
model_10l <- lmer(oto.width ~ coll.doy_standardized  + lat_standardized*sal.length_standardized + (1 | sal.id), data = herring_data, REML= FALSE)

model_11l <- lmer(oto.width ~ coll.doy_standardized + long_standardized*sal.length_standardized + (1 | sal.id), data = herring_data, REML= FALSE)

model_10c <- lmer(oto.width ~ coll.doy_standardized*sal.length_standardized + lat_standardized + (1 | sal.id), data = herring_data, REML= FALSE)

model_11c <- lmer(oto.width ~ coll.doy_standardized*sal.length_standardized + long_standardized + (1 | sal.id), data = herring_data, REML= FALSE)

#Models with three explanatory variables and two interaction terms
model_10cl <- lmer(oto.width ~ coll.doy_standardized*sal.length_standardized*lat_standardized + (1 | sal.id), data = herring_data, REML= FALSE)

model_11cl <- lmer(oto.width ~ coll.doy_standardized*sal.length_standardized*long_standardized + (1 | sal.id), data = herring_data, REML= FALSE)

```

##Running the AIC
```{r}
#Calculate AIC values
AIC_out <- AIC(model_0, model_1, model_2, model_3, model_4, model_5, model_6, model_7, model_8, model_9, model_5i, model_6i, model_7i, model_8i, model_9i, model_10, model_11, model_10l, model_10c, model_11l, model_11c, model_10cl, model_11cl)

#Calculate delta AIC values
AIC_out$delta_AIC <- AIC_out$AIC - min(AIC_out$AIC)

#Show AIC table with weights
AICtab(model_0, model_1, model_2, model_3, model_4, model_5, model_6, model_7, model_8, model_9, model_5i, model_6i, model_7i, model_8i, model_9i, model_10, model_11, model_10l, model_10c, model_11l, model_11c, model_10cl, model_11cl, base = TRUE, weights = TRUE)
```

##Summarizing model 11
```{r}
#Call coeﬃcient estimates for fixed effects
fixef(model_11)

#Call variation within and between salmon.id
VarCorr(model_11)

#Calculate conﬁdence intervals for coeﬃcient estimate
confint(model_11)

#Rearrange data for a plot of coefficients with standard errors
#Make data frame for plot of coefficients
confint_fixed_11 <- as.data.frame(confint(model_11, parm = c("(Intercept)", "coll.doy_standardized", "long_standardized", "sal.length_standardized")))

##Compute profile confidence intervals
confint_fixed_11 <- as.data.frame(confint_fixed_11)
confint_fixed_11$term <- rownames(confint_fixed_11)
confint_fixed_11$estimate <- fixef(model_11)

##ggplot
ggplot(confint_fixed_11) + 
  theme_bw() +
  geom_point(aes(y = term, x = estimate), colour = "midnightblue") +
  geom_errorbarh(aes(y = term, xmin = `2.5 %`, xmax = `97.5 %`), colour = "midnightblue", height = 0.3) +
  scale_y_discrete(labels = c("Intercept", "Collection Day of Year", "Longitude", "Salmon length")) +
  xlab("") +
  ylab("") + 
  ggtitle("Coefficient Estimates for model 11") +
  theme(axis.text = element_text(size = 14, colour = "black"))
```
##Summarizing model 6
```{r}
#Call coeﬃcient estimates for fixed effects
fixef(model_6)

#Call variation within and between salmon.id
VarCorr(model_6)

#Calculate conﬁdence intervals for coeﬃcient estimate
confint(model_6)

#Rearrange data for a plot of coefficients with standard errors
#Make data frame for plot of coefficients
confint_fixed_6 <- as.data.frame(confint(model_6, parm = c("(Intercept)", "coll.doy_standardized", "long_standardized")))

##Compute profile confidence intervals
confint_fixed_6 <- as.data.frame(confint_fixed_6)
confint_fixed_6$term <- rownames(confint_fixed_6)
confint_fixed_6$estimate <- fixef(model_6)

##ggplot
ggplot(confint_fixed_6) + 
  theme_bw() +
  geom_point(aes(y = term, x = estimate), colour = "midnightblue") +
  geom_errorbarh(aes(y = term, xmin = `2.5 %`, xmax = `97.5 %`), colour = "midnightblue", height = 0.3) +
  scale_y_discrete(labels = c("Intercept", "Collection Day of Year", "Longitude")) +
  xlab("") +
  ylab("") + 
  ggtitle("Coefficient Estimates for model 6") +
  theme(axis.text = element_text(size = 14, colour = "black"))
```
#Section 8: Plotting a Model with the Data
##Plot model 11
```{r, echo = TRUE}
#Create data frame for plot of model 11 predictions with longitude on the x axis
oto.width_vs_long_data_11 <- data.frame(long = seq(-125.29, -123.16, 0.001), coll.doy_standardized = median(herring_data$coll.doy_standardized), sal.length_standardized = median(herring_data$sal.length_standardized))

#Add standardized long data to data frame
oto.width_vs_long_data_11$long_standardized <- ((oto.width_vs_long_data_11$long - mean(oto.width_vs_long_data_11$long))/sd(oto.width_vs_long_data_11$long))

#Generate model predictions at population level 
oto.width_vs_long_data_11$fit_11_pop <- predict(model_11, newdata = oto.width_vs_long_data_11, re.form = ~0)

#Generate model predictions at salmon id level
herring_data$fit_11_sal.id <- predict(model_11)

#Plot the model vs. longitude
model_11_long <- ggplot(herring_data) +
  theme_minimal() + 
  geom_point(aes(long, oto.width), shape = 1, size = 0.2) +
  geom_line(aes(long, fit_11_pop), data = oto.width_vs_long_data_11) + 
  geom_point(aes(long, fit_11_sal.id, group = sal.id), shape = 2)

#Create data frame for plot of model 11 predictions with coll.doy on the x axis
oto.width_vs_coll.doy_data_11 <- data.frame(coll.doy = seq(1, 365, 1), long_standardized = median(herring_data$long_standardized), sal.length_standardized = median(herring_data$sal.length_standardized))

#Add standardized coll.doy data to data frame
oto.width_vs_coll.doy_data_11$coll.doy_standardized <- ((oto.width_vs_coll.doy_data_11$coll.doy - mean(oto.width_vs_coll.doy_data_11$coll.doy))/sd(oto.width_vs_coll.doy_data_11$coll.doy))

#Generate model predictions at population level 
oto.width_vs_coll.doy_data_11$fit_11_pop <- predict(model_11, newdata = oto.width_vs_coll.doy_data_11, re.form = ~0)

#Generate model predictions at salmon id level
herring_data$fit_11_sal.id <- predict(model_11)

#Plot the model vs.coll.doy
model_11_coll.doy <- ggplot(herring_data) +
  theme_minimal() + 
  geom_point(aes(coll.doy, oto.width), shape = 1, size = 0.2) +
  geom_line(aes(coll.doy, fit_11_pop), data = oto.width_vs_coll.doy_data_11) + 
  geom_point(aes(coll.doy, fit_11_sal.id, group = sal.id), shape = 2)

#Create data frame for plot of model 11 predictions with sal.length on the x axis
oto.width_vs_sal.length_data_11 <- data.frame(sal.length = seq(45, 96, 0.5), long_standardized = median(herring_data$long_standardized), coll.doy_standardized = median(herring_data$coll.doy_standardized))

#Add standardized sal.length data to data frame
oto.width_vs_sal.length_data_11$sal.length_standardized <- ((oto.width_vs_sal.length_data_11$sal.length - mean(oto.width_vs_sal.length_data_11$sal.length))/sd(oto.width_vs_sal.length_data_11$sal.length))

#Generate model predictions at population level 
oto.width_vs_sal.length_data_11$fit_11_pop <- predict(model_11, newdata = oto.width_vs_sal.length_data_11, re.form = ~0)

#Plot the model vs. sal.length
model_11_sal.length <- ggplot(herring_data) +
  theme_minimal() + 
  geom_point(aes(sal.length, oto.width), shape = 1, size = 0.2) +
  geom_line(aes(sal.length, fit_11_pop), data = oto.width_vs_sal.length_data_11) + 
  geom_point(aes(sal.length, fit_11_sal.id, group = sal.id), shape = 2)

grid.arrange(model_11_long, model_11_coll.doy, model_11_sal.length, nrow = 2)
```

##Plot model 6
```{r, echo = TRUE}
#Create data frame for plot of model 6 predictions with longitude on the x axis
oto.width_vs_long_data_6 <- data.frame(long = seq(-125.29, -123.16, 0.001), coll.doy_standardized = median(herring_data$coll.doy_standardized), sal.length_standardized = median(herring_data$sal.length_standardized))

#Add standardized long data to data frame
oto.width_vs_long_data_6$long_standardized <- ((oto.width_vs_long_data_6$long - mean(oto.width_vs_long_data_6$long))/sd(oto.width_vs_long_data_6$long))

#Generate model predictions at population level 
oto.width_vs_long_data_6$fit_6_pop <- predict(model_6, newdata = oto.width_vs_long_data_6, re.form = ~0)

#Generate model predictions at salmon id level
herring_data$fit_6_sal.id <- predict(model_6)

#Plot the model vs. longitude
model_6_long <- ggplot(herring_data) +
  theme_minimal() + 
  geom_point(aes(long, oto.width), shape = 1, size = 0.2) +
  geom_line(aes(long, fit_6_pop), data = oto.width_vs_long_data_6) + 
  geom_point(aes(long, fit_6_sal.id, group = sal.id), shape = 2)

#Create data frame for plot of model 6 predictions with coll.doy on the x axis
oto.width_vs_coll.doy_data_6 <- data.frame(coll.doy = seq(1, 365, 1), long_standardized = median(herring_data$long_standardized), sal.length_standardized = median(herring_data$sal.length_standardized))

#Add standardized coll.doy data to data frame
oto.width_vs_coll.doy_data_6$coll.doy_standardized <- ((oto.width_vs_coll.doy_data_6$coll.doy - mean(oto.width_vs_coll.doy_data_6$coll.doy))/sd(oto.width_vs_coll.doy_data_6$coll.doy))

#Generate model predictions at population level 
oto.width_vs_coll.doy_data_6$fit_6_pop <- predict(model_6, newdata = oto.width_vs_coll.doy_data_6, re.form = ~0)

#Generate model predictions at salmon id level
herring_data$fit_6_sal.id <- predict(model_6)

#Plot the model vs.coll.doy
model_6_coll.doy <- ggplot(herring_data) +
  theme_minimal() + 
  geom_point(aes(coll.doy, oto.width), shape = 1, size = 0.2) +
  geom_line(aes(coll.doy, fit_6_pop), data = oto.width_vs_coll.doy_data_6) + 
  geom_point(aes(coll.doy, fit_6_sal.id, group = sal.id), shape = 2)

#Create data frame for plot of model 6 predictions with sal.length on the x axis
oto.width_vs_sal.length_data_6 <- data.frame(sal.length = seq(45, 96, 0.5), long_standardized = median(herring_data$long_standardized), coll.doy_standardized = median(herring_data$coll.doy_standardized))

grid.arrange(model_6_long, model_6_coll.doy, nrow = 2)
```

#Section 9: Discussion (400 words)
##A)
Assessment of how well the model seems to ﬁt the data
- model checking
- visualization of the model with the data
- 
##B)
Qualitative interpretation of the model
- interpretation of results in relation to your research questions and hypotheses
- general interpretation of conﬁdence intervals or standard errors for coeﬃcient estimates
-
##C)
Limitations of the model(s) that you have ﬁt
- Limitations
- Possible options for improvement
- Possible approaches for further data analysis

##D)
Results into context
- citie at least two relevant scientiﬁc papers

## References

Schindler, D. E., M. D. Scheuerell, J. W. Moore, S. M. Gende, T. B. Francis, and W. J. Palen. 2003. Pacific Salmon and the Ecology of Coastal Ecosystems. Frontiers in Ecology and the Environment 1:31.

Stevenson, D. K., and S. E. Campana. 1992. Otolith microstructure examination and analysis. Can. Spec. Publ. Fish. Aquat. Sci. 117: 126 p. 1. Page Otolith Microstructure Examination and Analysis.

Bates, D., Maechler, M., Bolker, B., Walker, S., 2015. Fitting Linear Mixed-Effects Models Using lme4.
Journal of Statistical Software, 67 (1), 1-48.

